{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need Lib for Next Instractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python2.7\n",
    "# -*- coding: utf-8 -*-\n",
    "from Kuytu.wikiLog import KuytuLog\n",
    "from Kuytu.WikiDumpParser import WikiDumpParser\n",
    "import Kuytu.file_commander as K_fc\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create custom Log from Kuytu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = KuytuLog('BlackBoxCode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiki Dump Seperation Stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Giving Wiki-Dump XML path wait for seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------WIKI DUMP XML GETTING MEMORY----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ff59521bffec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'WIKI DUMP XML GETTING MEMORY'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#wdp = WikiDumpParser('./Data/wikidump.xml')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mwdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWikiDumpParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Data/wikidump.xml'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# A Part of The Orjinal WIKI-DUMP Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Starting to parse all page in XML file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/uluc/Desktop/SIU_Makele_ 2/WorkSpace/Codes/Kuytu/WikiDumpParser.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_box_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#generation of tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/xml/etree/ElementTree.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/xml/etree/ElementTree.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    654\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                 \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/xml/etree/ElementTree.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raiseerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/xml/etree/ElementTree.pyc\u001b[0m in \u001b[0;36m_end\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fixname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_comment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/xml/etree/ElementTree.pyc\u001b[0m in \u001b[0;36mend\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/xml/etree/ElementTree.pyc\u001b[0m in \u001b[0;36m_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1391\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"internal error (tail)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----------- WIKI DUMP XML PARSE ------------------------------- Execution ----\n",
    "# XML Getting Memory\n",
    "print '-'*10 + 'WIKI DUMP XML GETTING MEMORY' + '-'*10 \n",
    "#wdp = WikiDumpParser('./Data/wikidump.xml')\n",
    "wdp = WikiDumpParser('./Data/wikidump.xml') # A Part of The Orjinal WIKI-DUMP Data\n",
    "\n",
    "# Starting to parse all page in XML file\n",
    "print '-'*14 + 'WIKI DUMP PARSE START' + '-'*13\n",
    "wdp.extract_pages(StoreAllText = False, NumberofParagraph = 2 )\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After Seperation saving Seperation Log to our 'Kuytu_log' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- WIKI DUMP XML PARSE -------------- Save Log Info (of execution)---\n",
    "# non_article_count, no_infoBox_count, error_count, number_of_total_article, number_of_article_has_infoBox\n",
    "log.save_log('WIKI DUMP PARSE - RESULT', json.dumps(wdp.getLog(),indent=4,ensure_ascii=False, encoding='utf8') )\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Take the  [Uniq Info Box Type - Hit Count] data and Graph it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- WIKI DUMP XML PARSE -------------- Save Uniq InfoBoxCounts (B.K.)-\n",
    "output_path = log.get_output_path()\n",
    "#print json.dumps( wdp.get_uniqInfoBoxTypes(),indent=4,ensure_ascii=False, encoding='utf8')\n",
    "K_fc.save_Uniq_InfoBoxTypes( output_path + '/Uniq-BK-Types-Hit-Counts.txt', wdp.get_uniqInfoBoxTypes() )\n",
    "K_fc.save_Graph( output_path = output_path\n",
    "                ,data = wdp.get_uniqInfoBoxTypes()\n",
    "                ,min_repetition = 100\n",
    "                ,title = 'Uniq-BK-Types-Hit-Counts-Graph(>100)' )\n",
    "log.logging('Uniq-BK-Types-Hit-Counts-Graph(>100) Saved')\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save The Seperated Pages in 3 Group\n",
    "    -> Template of the returnin valu of wdp.get_all_articles()\n",
    "    { \n",
    "        \"withInfoBox_articles_list\" \t: [....articleObject...],\n",
    "        \"withOUTInfoBox_articles_list\"  : [..(article_XML_TEXT,Article_Title,Article_Id)..],\n",
    "        \"NonStandart_articles_list\" \t: [..article_XML_TEXT..]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- WIKI DUMP XML PARSE ----------------------- Save Article Pages ---\n",
    "allArticles = wdp.get_all_articles()\n",
    "\n",
    "\n",
    "# Pages WithOut InfoBox \n",
    "withOUTInfoBoxPagesXMLPath = output_path + 'BulkData/withOUTInfoBoxPages_bulkXML.xml'\n",
    "withOUTInfoBoxPagesIndexPath = output_path + 'BulkData/withOUTInfoBoxPages_bulkXML_index.txt'\n",
    "l1 = K_fc.save_XML(withOUTInfoBoxPagesXMLPath, withOUTInfoBoxPagesIndexPath, allArticles['withOUTInfoBox_articles_list'] )\n",
    "\n",
    "# Pages With InfoBox \n",
    "StandartPagesXMLPath = output_path + 'BulkData/withInfoBoxPages_bulkXML.xml'\n",
    "StandartPagesIndexPath = output_path + 'BulkData/withInfoBoxPages_bulkXML_index.txt'\n",
    "l2 = K_fc.save_XML(StandartPagesXMLPath, StandartPagesIndexPath, allArticles['withInfoBox_articles_list'] )\n",
    "\n",
    "# Pages - NonStandart\n",
    "nonStandartPagesXMLPath = output_path + 'BulkData/NonStandartPages_bulkXML.xml'\n",
    "nonStandartPagesIndexPath = output_path + 'BulkData/NonStandartPages_bulkXML_index.txt'\n",
    "l3 = K_fc.save_XML(nonStandartPagesXMLPath, nonStandartPagesIndexPath, allArticles['NonStandart_articles_list'] )\n",
    "\n",
    "log.logging([l1,l2,l3])  ## Save '.save_XML' log.\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### First part of the Wiki Full Extraction is finished\n",
    "\n",
    "#### The Outputs are ;\n",
    "![alttext](https://raw.githubusercontent.com/UlucFVardar/Kuytu/master/Examples/Output_of_seperation.png)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Cleaning The Parsed Data (With InfoBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Kuytu.Analyzer as Analyzer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### When code runs from begining\n",
    "Articles_with_BK = allArticles['withInfoBox_articles_list']\n",
    "allArticles = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "log = KuytuLog('BlackBoxCode','r')\n",
    "output_path = log.get_output_path()\n",
    "\n",
    "StandartPagesXMLPath = output_path + 'BulkData/withInfoBoxPages_bulkXML.xml'\n",
    "\n",
    "Articles_with_BK = K_fc.read_XML(StandartPagesXMLPath)\n",
    "\n",
    "\n",
    "#---------\n",
    "StandartPagesXMLPath = output_path + 'test_data.xml'\n",
    "Articles_with_BK = K_fc.read_XML(StandartPagesXMLPath)\n",
    "\n",
    "'''\n",
    "#---------\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### when code starts to run here \n",
    "from Kuytu.wikiLog import KuytuLog\n",
    "from Kuytu.WikiDumpParser import WikiDumpParser\n",
    "import Kuytu.file_commander as K_fc\n",
    "import json\n",
    "\n",
    "log = KuytuLog('BlackBoxCode','r')\n",
    "output_path = log.get_output_path()\n",
    "\n",
    "StandartPagesXMLPath = '../test_data.xml'\n",
    "\n",
    "#StandartPagesXMLPath = output_path + 'BulkData/withInfoBoxPages_bulkXML.xml'\n",
    "\n",
    "Articles_with_BK = K_fc.read_XML(StandartPagesXMLPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving  Histogram of Clean DA's owned Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uniq_types = map(lambda a : a.get_infoBox_type() , Articles_with_BK)\n",
    "c = Counter( uniq_types )\n",
    "uniq_types_histogram = list(c.items())\n",
    "\n",
    "output_path = log.get_output_path()\n",
    "#print json.dumps( wdp.get_uniqInfoBoxTypes(),indent=4,ensure_ascii=False, encoding='utf8')\n",
    "K_fc.save_Uniq_InfoBoxTypes( output_path + '/Uniq-BK-Types-Hit-Counts-Graph-Clean(>100).txt', uniq_types_histogram )\n",
    "K_fc.save_Graph( output_path = output_path\n",
    "                ,data = uniq_types_histogram\n",
    "                ,min_repetition = 2\n",
    "                ,title = 'Uniq-BK-Types-Hit-Counts-Graph-Clean(>100)' )\n",
    "log.logging('Uniq-BK-Types-Hit-Counts-Graph-Clean(>100) Saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### According to histogram graphs ınterested domain can be seperated \n",
    "\n",
    "\n",
    "# Seperation Interested Domain Related Info Box Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Articles interested categories 76\n"
     ]
    }
   ],
   "source": [
    "Interested_Info_Box_Types = [ u'Hakem' ,u'Manken' ,u'Makam Sahibi' ,u'Filozof' ,u'Bilim Insanı',u'Güreşçi' \n",
    "                             ,u'Bilim Adamı' ,u'Sporcu' ,u'Buz Patencisi',u'Asker' \n",
    "                             ,u'Voleybolcu' ,u'Sanatçı',u'Futbolcu' ,u'Oyuncu' \n",
    "                             ,u'Müzik Sanatçısı' ,u'Yazar' ,u'Kraliyet' ,u'Tenis Sporcu' ,u'Profesyonel Güreşçi'\n",
    "                             ,u'Kişi' ,u'Basketbolcu']\n",
    "str_of_BKs = json.dumps(Interested_Info_Box_Types,indent = 4,ensure_ascii=False, encoding='utf8').encode('utf-8')\n",
    "log.save_log('Interested ınfoBoxes are', str_of_BKs )\n",
    "Interested_articles_with_BK =  filter(lambda a: a.get_infoBox_type() in Interested_Info_Box_Types , Articles_with_BK)\n",
    "\n",
    "\n",
    "prt_log = '#Articles interested categories '+ str(len(Interested_articles_with_BK))\n",
    "\n",
    "log.logging(prt_log)\n",
    "print prt_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### After the seperation for a certain set of articles can clean\n",
    "    - InfoBox fields will clean - many banned key or value can be setted.\n",
    "    \n",
    "    - Choosen first n paragraphs will clean\n",
    "    \n",
    "    - All text of articles will clean\n",
    "    \n",
    "\n",
    "# Cleaning The Texts of Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning Info Boxes Generally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burda 1\n",
      "burda 5\n",
      "burda 6\n",
      "burda 7\n",
      "{{M.Ö. 570}} burdaa\n",
      "{{M.Ö. 495}} burdaa\n",
      "{{26 Ağustos veya Doğum tarihi|1451|10|31}} burdaa\n",
      "{{4 Ekim 1919 ve 2 Ekim 1920 arasında}} burdaa\n",
      "{{MÖ 469}} burdaa\n"
     ]
    }
   ],
   "source": [
    "from Kuytu.article_cleaner_kit import clean_InfoBoxBulk \n",
    "\n",
    "for i,article in enumerate(Interested_articles_with_BK):\n",
    "    \n",
    "    # read \n",
    "    bulk_BK_of_article  = article.get_infoBoxText()\n",
    "    # clean\n",
    "    clean_BK_of_article = clean_InfoBoxBulk(bulk_BK_of_article)\n",
    "    # write\n",
    "    Interested_articles_with_BK[i].set_infoBox_clean(clean_BK_of_article)\n",
    "    \n",
    "# Eliminate None parsed articles\n",
    "Interested_articles_with_BK_clean =  filter(lambda a: a.get_cleanInfoBox() != None , Interested_articles_with_BK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paragraph Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kuytu.article_cleaner_kit import clean_paragraphs\n",
    "\n",
    "for i,article in enumerate(Interested_articles_with_BK_clean):\n",
    "    # read \n",
    "    paragraphs_of_article  = article.get_bulkParagraphs()\n",
    "    # clean\n",
    "    cleaned_paragraphs = clean_paragraphs(paragraphs_of_article)\n",
    "    # write\n",
    "    Interested_articles_with_BK_clean[i].set_cleanParagraphs(cleaned_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kuytu.article_cleaner_kit import clean_bulk_text\n",
    "\n",
    "for i,article in enumerate(Interested_articles_with_BK_clean):\n",
    "    # read \n",
    "    bulk_text_of_article  = article.get_allBulkText()\n",
    "    # clean\n",
    "    cleaned_text = clean_bulk_text(bulk_text_of_article)\n",
    "    # write\n",
    "    Interested_articles_with_BK_clean[i].set_cleanText(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split First 2 sentences with java Zemberek and custom regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#\n",
    "# SENTENCES\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Articles parsed clean(InfoBoxes-Paragraphs-AllText-Sentences) 75\n"
     ]
    }
   ],
   "source": [
    "prt_log = '#Articles parsed clean(InfoBoxes-Paragraphs-AllText-Sentences) '+ str(len(Interested_articles_with_BK_clean))\n",
    "log.logging(prt_log)\n",
    "print prt_log    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### According to cleaned Info Boxes data can investigating\n",
    "    - For each InfoBoxType that interested articles can be seperated.\n",
    "    \n",
    "    - 2 different name but nearly same types can make one\n",
    "    \n",
    "    - Info Boxes data field keys can be mapped to certain value\n",
    "\n",
    "\n",
    "#  Analysis and Manipulating the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperated_interested_articles = Analyzer.seperate_articles_according_to_type(Interested_articles_with_BK_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### format of 'seperated_interested_articles'\n",
    "    {\n",
    "     \"ınfo_box_type_1\" : [.....list of articles....],\n",
    "     \"ınfo_box_type_2\" : [.....list of articles....],\n",
    "     \"ınfo_box_type_3\" : [.....list of articles....],\n",
    "     \"ınfo_box_type_4\" : [.....list of articles....],\n",
    "     \"ınfo_box_type_5\" : [.....list of articles....],\n",
    "     \"ınfo_box_type_6\" : [.....list of articles....]\n",
    "     }\n",
    "     \n",
    "     \n",
    "##### Same domain Type merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i,a in enumerate(seperated_interested_articles[u\"Bilim Adamı\"]):\n",
    "        seperated_interested_articles[u\"Bilim Adamı\"][i].set_infoBox_type(u'Bilim Insanı')\n",
    "    seperated_interested_articles[u\"Bilim Insanı\"] += seperated_interested_articles[u\"Bilim Adamı\"]        \n",
    "    del seperated_interested_articles[u\"Bilim Adamı\"]\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mapping Certain Info Box Types Keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_ = {\n",
    "    u'Manken' :{\n",
    "        \"yer\" : \"doğumyeri\"\n",
    "    },\n",
    "    u'Hakem' : {\n",
    "        \"etkinyıl\" : \"aktifyıl\",\n",
    "        \"yıl\" : \"aktifyıl\",\n",
    "        \"yer\" : \"doğumyeri\"\n",
    "    }\n",
    "}         \n",
    "seperated_interested_articles = Analyzer.datafield_map(map_, seperated_interested_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Fields Counting of InfoBoxes Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count_data, count_data = Analyzer.data_field_counter(seperated_interested_articles)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = log.get_output_path()\n",
    "total_article_count = float(len(Interested_articles_with_BK_clean))\n",
    "subcats_article_counts =  { type_ :float(len(list_)) for type_,list_ in seperated_interested_articles.items()}\n",
    "\n",
    "Analyzer.save_count_data( path = output_path + 'Counts'\n",
    "                        , total_count_data =  total_count_data\n",
    "                        , count_data = count_data\n",
    "                        , total_first_n = 100\n",
    "                        , subcat_first_n = 20\n",
    "                        , total_article_count = total_article_count\n",
    "                        , subcats_article_counts = subcats_article_counts )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the Data Field Count of The InfoBox Types\n",
    "\n",
    "#### The Outputs are ;\n",
    "![alttext](./ss/counter_ex.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### with the knowlegde of count of datafields for each interested category only some of the datafields can be stored\n",
    "\n",
    "\n",
    "# Deleting Un-Needed Datafields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_datafields =  {\n",
    "    u\"Hakem\" :               [\"ad\",\"doğumtarihi\" ,\"turnuva\"    ,\"aktifyıl\",\"doğumyeri\"],\n",
    "    u\"Sporcu\" :              [\"ad\",\"doğumtarihi\" ,\"spor\"       ,\"doğumyeri\",\"ülke\"],\n",
    "    u\"Kraliyet\"  :           [\"ad\",\"doğumtarihi\" ,\"hanedan\"    ,\"hükümsüresi\",\"ölümtarihi\"],\n",
    "    u\"Voleybolcu\" :          [\"ad\",\"doğumtarihi\" ,\"pozisyon\"   ,\"doğumyeri\"],\n",
    "    u\"Manken\" :              [\"ad\",\"doğumtarihi\" ,\"ulus\"       ,\"doğumyeri\"],\n",
    "    u\"Oyuncu\" :              [\"ad\",\"doğumtarihi\" ,\"meslek\"     ,\"yer\",\"ölümtarihi\"],\n",
    "    u\"Asker\" :               [\"ad\",\"doğumtarihi\" ,\"rütbesi\"    ,\"doğumyeri\",\"ölümtarihi\"],\n",
    "    u\"Makam Sahibi\" :        [\"ad\",\"doğumtarihi\" ,\"makam\"      ,\"doğumyeri\"],\n",
    "    u\"Buz Patencisi\" :       [\"ad\",\"doğumtarihi\" ,\"ülke\"       ,\"koç\"],\n",
    "    u\"Profesyonel Güreşçi\" : [\"ad\",\"doğumtarihi\" ,\"doğumyeri\"],\n",
    "    u\"Kişi\" :                [\"ad\",\"doğumtarihi\" ,\"meslek\"     ,\"doğumyeri\",\"ölümtarihi\"],\n",
    "    u\"Futbolcu\" :            [\"ad\",\"doğumyeri\"   ,\"pozisyon\"   ,\"doğumtarihi\"],\n",
    "    u\"Tenis Sporcu\" :        [\"ad\",\"doğumyeri\"   ,\"oyunstili\"  ,\"doğumtarihi\"],\n",
    "    u\"Bilim Insanı\" :        [\"ad\",\"doğumyeri\"   ,\"dalı\"       ,\"doğumtarihi\"],\n",
    "    u\"Filozof\" :             [\"ad\",\"doğumyeri\"   ,\"doğumtarihi\",\"çağ\"],\n",
    "    u\"Basketbolcu\" :         [\"ad\",\"doğumyeri\"   ,\"pozisyon\"   ,\"doğumtarihi\"],\n",
    "    u\"Güreşçi\" :             [\"ad\",\"doğumyeri\"   ,\"doğumtarihi\",\"ölümtarihi\"],\n",
    "    u\"Yazar\" :               [\"ad\",\"doğumyeri\"   ,\"meslek\"     ,\"doğumtarihi\",\"ölümtarihi\"],\n",
    "    u\"Müzik Sanatçısı\":      [\"ad\",\"artalan\"     ,\"tarz\"       ,\"etkinyıllar\",\"meslek\"],\n",
    "    u\"Sanatçı\" :             [\"ad\",\"alanı\"       ,\"ölümtarihi\" ,\"ölümyeri\"]\n",
    "}\n",
    "seperated_interested_articles_hold_interested_DF = Analyzer.hold_interested_datafields(interested_datafields, seperated_interested_articles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_ in seperated_interested_articles_hold_interested_DF.keys():\n",
    "    seperated_interested_articles_hold_interested_DF[type_] = filter(lambda a : len(a.get_cleanInfoBox().keys()) != 0 , seperated_interested_articles_hold_interested_DF[type_] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Saving The ~Clean Result Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = output_path + 'CleanData/clean_data_EXCEL.xlsx'\n",
    "K_fc.export_data_2_excel(excel_path,seperated_interested_articles_hold_interested_DF,interested_datafields)\n",
    "\n",
    "log.logging('CLEAN DATA SAVED TO EXCEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XML save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!--     73 Article Saved Successfully -- FileName(             clean_data_XML.xml)----------!\n"
     ]
    }
   ],
   "source": [
    "all_clean_articles = [ seperated_interested_articles_hold_interested_DF[type_] for type_ in seperated_interested_articles_hold_interested_DF.keys()]\n",
    "all_clean_articles = sum(all_clean_articles, [])\n",
    "# Pages With InfoBox \n",
    "StandartPagesXMLPath = output_path + 'CleanData/clean_data_XML.xml'\n",
    "StandartPagesIndexPath = output_path + 'CleanData/clean_data_XML_index.txt'\n",
    "l2 = K_fc.save_XML(StandartPagesXMLPath, StandartPagesIndexPath, all_clean_articles, 'clean')\n",
    "\n",
    "log.logging(['CLEAN DATA SAVED TO XML with INDEX',l2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Txt_File_path = output_path + 'CleanData/clean_data_JSON.json'\n",
    "K_fc.save_txt_file(Txt_File_path, all_clean_articles)\n",
    "\n",
    "log.logging('CLEAN DATA SAVED TO JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
